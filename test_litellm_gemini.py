#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LiteLLMè°ƒç”¨Geminiæµ‹è¯•
ä¸“é—¨æµ‹è¯•é€šè¿‡LiteLLMè°ƒç”¨Google Geminiçš„å„ç§æ–¹å¼
"""

import os
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

def test_litellm_gemini_models():
    """æµ‹è¯•ä¸åŒçš„Geminiæ¨¡å‹"""
    try:
        import litellm
        
        # æ£€æŸ¥APIå¯†é’¥
        api_key = os.getenv('GOOGLE_API_KEY')
        if not api_key:
            print("âŒ é”™è¯¯: æœªè®¾ç½®GOOGLE_API_KEYç¯å¢ƒå˜é‡")
            return False
            
        # è®¾ç½®ç¯å¢ƒå˜é‡
        os.environ['GOOGLE_API_KEY'] = api_key
        
        print(f"âœ… æ‰¾åˆ°Google APIå¯†é’¥: {api_key[:10]}...")
        
        # æµ‹è¯•ä¸åŒçš„Geminiæ¨¡å‹
        models_to_test = [
            "gemini/gemini-1.5-flash",
            "gemini/gemini-2.5-pro",
            # "vertex_ai/gemini-1.5-flash",
            # "vertex_ai/gemini-1.5-pro"
        ]
        
        successful_models = []
        
        for model in models_to_test:
            print(f"\nğŸ§ª æµ‹è¯•æ¨¡å‹: {model}")
            try:
                response = litellm.completion(
                    model=model,
                    messages=[
                        {"role": "user", "content": "è¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±ã€‚"}
                    ],
                    temperature=0.1,
                    max_tokens=100
                )
                
                content = response.choices[0].message.content
                print(f"âœ… æˆåŠŸ: {content[:80]}...")
                successful_models.append(model)
                
            except Exception as e:
                print(f"âŒ å¤±è´¥: {str(e)[:100]}...")
        
        if successful_models:
            print(f"\nâœ… æˆåŠŸçš„æ¨¡å‹: {', '.join(successful_models)}")
            return True
        else:
            print("\nâŒ æ‰€æœ‰æ¨¡å‹æµ‹è¯•éƒ½å¤±è´¥äº†")
            return False
            
    except ImportError as e:
        print(f"âŒ å¯¼å…¥é”™è¯¯: {e}")
        print("è¯·å®‰è£…: pip install litellm")
        return False
    except Exception as e:
        print(f"âŒ æµ‹è¯•é”™è¯¯: {e}")
        return False

def test_litellm_with_crewai_format():
    """æµ‹è¯•LiteLLMåœ¨CrewAIä¸­çš„ä½¿ç”¨æ ¼å¼"""
    try:
        import litellm
        
        # æ£€æŸ¥APIå¯†é’¥
        api_key = os.getenv('GOOGLE_API_KEY')
        if not api_key:
            print("âŒ é”™è¯¯: æœªè®¾ç½®GOOGLE_API_KEYç¯å¢ƒå˜é‡")
            return False
            
        os.environ['GOOGLE_API_KEY'] = api_key
        
        print("âœ… æµ‹è¯•CrewAIæ ¼å¼çš„LiteLLMè°ƒç”¨...")
        
        # æ¨¡æ‹ŸCrewAIçš„è°ƒç”¨æ–¹å¼
        def create_llm_response(prompt):
            """æ¨¡æ‹ŸCrewAIä¸­LLMçš„è°ƒç”¨"""
            response = litellm.completion(
                model="gemini/gemini-1.5-flash",
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,
                max_tokens=500
            )
            return response.choices[0].message.content
        
        # æµ‹è¯•ä¸åŒç±»å‹çš„ä»»åŠ¡
        test_prompts = [
            "è¯·åˆ†æä¸€ä¸ªåœ¨çº¿å›¾ä¹¦ç®¡ç†ç³»ç»Ÿçš„éœ€æ±‚ã€‚",
            "è®¾è®¡ä¸€ä¸ªç®€å•çš„æ•°æ®åº“æ¶æ„ã€‚",
            "ç¼–å†™ä¸€ä¸ªPythonå‡½æ•°æ¥å¤„ç†ç”¨æˆ·ç™»å½•ã€‚"
        ]
        
        for i, prompt in enumerate(test_prompts, 1):
            print(f"\nğŸ“ æµ‹è¯•ä»»åŠ¡ {i}: {prompt[:30]}...")
            try:
                response = create_llm_response(prompt)
                print(f"âœ… å“åº”: {response[:100]}...")
            except Exception as e:
                print(f"âŒ å¤±è´¥: {e}")
                return False
        
        return True
        
    except Exception as e:
        print(f"âŒ CrewAIæ ¼å¼æµ‹è¯•é”™è¯¯: {e}")
        return False

def create_crewai_compatible_wrapper():
    """åˆ›å»ºCrewAIå…¼å®¹çš„LLMåŒ…è£…å™¨"""
    wrapper_code = '''
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CrewAIå…¼å®¹çš„LiteLLMåŒ…è£…å™¨
ç”¨äºåœ¨CrewAIä¸­ä½¿ç”¨LiteLLMè°ƒç”¨Gemini
"""

import os
import litellm
from typing import Any, Dict, List, Optional

class LiteLLMWrapper:
    """LiteLLMåŒ…è£…å™¨ï¼Œå…¼å®¹CrewAIçš„LLMæ¥å£"""
    
    def __init__(self, model: str = "gemini/gemini-1.5-flash", **kwargs):
        self.model = model
        self.temperature = kwargs.get('temperature', 0.1)
        self.max_tokens = kwargs.get('max_tokens', 1000)
        
        # ç¡®ä¿APIå¯†é’¥å·²è®¾ç½®
        if not os.getenv('GOOGLE_API_KEY'):
            raise ValueError("è¯·è®¾ç½®GOOGLE_API_KEYç¯å¢ƒå˜é‡")
    
    def invoke(self, prompt: str) -> Any:
        """å…¼å®¹LangChainçš„invokeæ–¹æ³•"""
        try:
            response = litellm.completion(
                model=self.model,
                messages=[
                    {"role": "user", "content": prompt}
                ],
                temperature=self.temperature,
                max_tokens=self.max_tokens
            )
            
            # åˆ›å»ºå…¼å®¹çš„å“åº”å¯¹è±¡
            class Response:
                def __init__(self, content):
                    self.content = content
            
            return Response(response.choices[0].message.content)
            
        except Exception as e:
            raise Exception(f"LiteLLMè°ƒç”¨å¤±è´¥: {e}")
    
    def __call__(self, prompt: str) -> str:
        """ç›´æ¥è°ƒç”¨æ–¹æ³•"""
        response = self.invoke(prompt)
        return response.content

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    from dotenv import load_dotenv
    load_dotenv()
    
    # åˆ›å»ºLLMå®ä¾‹
    llm = LiteLLMWrapper(model="gemini/gemini-1.5-flash")
    
    # æµ‹è¯•è°ƒç”¨
    response = llm.invoke("ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚")
    print(f"å“åº”: {response.content}")
'''
    
    with open('litellm_wrapper.py', 'w', encoding='utf-8') as f:
        f.write(wrapper_code)
    
    print("âœ… å·²åˆ›å»ºCrewAIå…¼å®¹çš„LiteLLMåŒ…è£…å™¨: litellm_wrapper.py")

def show_integration_guide():
    """æ˜¾ç¤ºé›†æˆæŒ‡å—"""
    print("\n" + "=" * 60)
    print("CrewAIé›†æˆLiteLLM GeminiæŒ‡å—")
    print("=" * 60)
    
    guide = """
1. å®‰è£…ä¾èµ–:
   pip install litellm python-dotenv

2. è®¾ç½®ç¯å¢ƒå˜é‡(.envæ–‡ä»¶):
   GOOGLE_API_KEY=your_google_api_key_here

3. åœ¨CrewAIä¸­ä½¿ç”¨LiteLLM:
   
   æ–¹æ³•ä¸€: ç›´æ¥ä½¿ç”¨LiteLLM
   ```python
   import litellm
   import os
   
   os.environ['GOOGLE_API_KEY'] = 'your_key'
   
   response = litellm.completion(
       model="gemini/gemini-1.5-flash",
       messages=[{"role": "user", "content": "Hello"}]
   )
   ```
   
   æ–¹æ³•äºŒ: ä½¿ç”¨åŒ…è£…å™¨
   ```python
   from litellm_wrapper import LiteLLMWrapper
   
   llm = LiteLLMWrapper(model="gemini/gemini-1.5-flash")
   
   # åœ¨CrewAI Agentä¸­ä½¿ç”¨
   agent = Agent(
       role='åŠ©æ‰‹',
       goal='å¸®åŠ©ç”¨æˆ·',
       backstory='æˆ‘æ˜¯AIåŠ©æ‰‹',
       llm=llm  # ä½¿ç”¨åŒ…è£…å™¨
   )
   ```

4. å¯ç”¨çš„Geminiæ¨¡å‹:
   - gemini/gemini-1.5-flash (æ¨èï¼Œé€Ÿåº¦å¿«)
   - gemini/gemini-1.5-pro (åŠŸèƒ½å¼ºå¤§)
   - vertex_ai/gemini-1.5-flash (é€šè¿‡Vertex AI)
   - vertex_ai/gemini-1.5-pro (é€šè¿‡Vertex AI)

5. æ•…éšœæ’é™¤:
   - ç¡®ä¿APIå¯†é’¥æœ‰æ•ˆ
   - æ£€æŸ¥ç½‘ç»œè¿æ¥
   - æŸ¥çœ‹LiteLLMæ–‡æ¡£: https://docs.litellm.ai/
"""
    
    print(guide)

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("=" * 60)
    print("LiteLLMè°ƒç”¨Geminiä¸“é¡¹æµ‹è¯•")
    print("=" * 60)
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    if not os.getenv('GOOGLE_API_KEY'):
        print("\nâš ï¸  è­¦å‘Š: æœªè®¾ç½®GOOGLE_API_KEYç¯å¢ƒå˜é‡")
        print("è¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®æ‚¨çš„Google APIå¯†é’¥")
        return
    
    tests = [
        ("LiteLLM Geminiæ¨¡å‹æµ‹è¯•", test_litellm_gemini_models),
        ("CrewAIæ ¼å¼å…¼å®¹æ€§æµ‹è¯•", test_litellm_with_crewai_format)
    ]
    
    results = []
    for test_name, test_func in tests:
        print(f"\nğŸ§ª {test_name}")
        print("-" * 40)
        result = test_func()
        results.append((test_name, result))
        print()
    
    # åˆ›å»ºåŒ…è£…å™¨
    print("\nğŸ”§ åˆ›å»ºCrewAIå…¼å®¹åŒ…è£…å™¨")
    print("-" * 40)
    create_crewai_compatible_wrapper()
    
    # æ€»ç»“
    print("\n" + "=" * 60)
    print("æµ‹è¯•ç»“æœæ€»ç»“")
    print("=" * 60)
    for test_name, result in results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{status} {test_name}")
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    print(f"\næ€»è®¡: {passed}/{total} ä¸ªæµ‹è¯•é€šè¿‡")
    
    # æ˜¾ç¤ºé›†æˆæŒ‡å—
    show_integration_guide()

if __name__ == "__main__":
    main()